{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff1c9d1-8a5f-437f-8b50-68c7aa8589e3",
   "metadata": {},
   "source": [
    "# A \"skeleton\" model explaining the Hybrid QML in PennyLane\n",
    "\n",
    "_This notebook explores the creation of a \"skeleton\" hybrid model in **PennyLane and PyTorch**_.\n",
    "\n",
    "**By:** Jacob Cybulski ([website](https://jacobcybulski.com/))<br>\n",
    "**Date:** Sptember 26, 2025<br>\n",
    "**Updates:** October 8, 2025<br>\n",
    "**Aims:** To develop a small hybrid model consisting of dummy components, such as quantum circuits, functions and matrices acting on data.<br/>\n",
    "**Prerequisites:** We will assume your knowledge of *QML* and *PennyLane* with *Python*<br>\n",
    "**License:** \n",
    "This project is licensed under the [GPL-3.0](https://www.gnu.org/licenses/gpl-3.0.txt)<br>\n",
    "**Changes:** All changes to this code must be listed at the bottom of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50523de-6808-4e6e-80a6-4fe50ef945e5",
   "metadata": {},
   "source": [
    "**Example:**<br>\n",
    ">Let's say we want to create a differentiable and trainable function $f$, defined as a network of functions $(f2)$, quantum circuits $(c1, c2, c3)$ and matrices $(m1)$, acting on data $(d1, d2)$. For example, in the form:<br>\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(d1, d2) = m1(c3(& && \\textit{Join and transform}\\\\\n",
    "                  &c1(d1), && \\textit{Branch 1}\\\\\n",
    "                  &c2(f2(d2)))) && \\textit{Branch 2}\n",
    "\\end{align*}\n",
    "$$\n",
    "What kind of code glue would be required to achieve this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b4af5b-6921-4ac1-b8fb-37898dc32ad0",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5414d159-eb04-455e-9c07-c0d0e2fef5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7003652c-a372-4c48-88d2-53070d88bbf1",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e250190c-bdf8-4fb7-8d7a-535c9bd3abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data sizes\n",
    "N_FEATURES_D1 = 3\n",
    "N_FEATURES_D2 = 5\n",
    "\n",
    "### Circuits I/O sizes\n",
    "#   We'll use the number of wires for C1 and C2\n",
    "#      as there are data features on their input\n",
    "#   C3 will need to handle their combined output\n",
    "N_WIRES_C1 = N_FEATURES_D1\n",
    "N_WIRES_C2 = N_FEATURES_D2\n",
    "N_WIRES_C3 = N_WIRES_C1 + N_WIRES_C2\n",
    "\n",
    "### Devices for different circuits\n",
    "dev_c1 = qml.device(\"default.qubit\", wires=N_WIRES_C1)\n",
    "dev_c2 = qml.device(\"default.qubit\", wires=N_WIRES_C2)\n",
    "dev_c3 = qml.device(\"default.qubit\", wires=N_WIRES_C3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637b4fec-52cc-42be-af5f-0c9e26c09ce3",
   "metadata": {},
   "source": [
    "##  Circuit definition\n",
    "*A batch size refers to the number of examples on input*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798262fb-573f-42bd-bdce-dd2cadd9e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### c1: Acts on data d1\n",
    "#   Processes N_WIRES_C1 features and outputs N_WIRES_C1 expectation values\n",
    "@qml.qnode(dev_c1, interface=\"torch\")\n",
    "def C1(inputs, weights):\n",
    "    qml.AngleEmbedding(inputs, wires=range(N_WIRES_C1))\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(N_WIRES_C1))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(N_WIRES_C1)]\n",
    "\n",
    "### c2: Acts on the output of f2(d2)\n",
    "#   Same structure as c1\n",
    "@qml.qnode(dev_c2, interface=\"torch\")\n",
    "def C2(inputs, weights):\n",
    "    qml.AngleEmbedding(inputs, wires=range(N_WIRES_C2))\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(N_WIRES_C2))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(N_WIRES_C2)]\n",
    "\n",
    "### c3: Acts on the combined output of c1 and c2\n",
    "#   Needs to have N_WIRES_C3 features\n",
    "@qml.qnode(dev_c3, interface=\"torch\")\n",
    "def C3(inputs, weights):\n",
    "    qml.AngleEmbedding(inputs, wires=range(N_WIRES_C3))\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(N_WIRES_C3))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(N_WIRES_C3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb85060-a0ef-46be-9a43-bd9499d896b2",
   "metadata": {},
   "source": [
    "## The entire hybrid model\n",
    "*Here instead of a full 2D matrix, we use a simple linear transformation. For a more complex matrix transform, we can pass the matrix at the model initialisation and then apply it using torch.matmul() in the forward step.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b8813ab-cf4f-4573-8389-f99f5c1290c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model of function f in Torch with PennyLane layers\n",
    "class HybridF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # f2: A simple classical linear transformation (NN)\n",
    "        #     Input features must match d2 dimensions\n",
    "        #     Output features must match c2 input\n",
    "        self.f2 = nn.Sequential(\n",
    "            nn.Linear(in_features=N_FEATURES_D2, out_features=2*N_FEATURES_D2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=2*N_FEATURES_D2, out_features=N_WIRES_C2)\n",
    "        )\n",
    "        \n",
    "        # m1: Final linear matrix transformation\n",
    "        #     Input features must match c3 output\n",
    "        self.m1 = nn.Linear(in_features=N_WIRES_C3, out_features=1)\n",
    "\n",
    "        # c1, c2, c3: All quantum components are Torch layers\n",
    "        #     Weight shapes now match the number of wires in c1, c2 and c3\n",
    "        c1_weight_shapes = {\"weights\": (1, N_WIRES_C1)}\n",
    "        c2_weight_shapes = {\"weights\": (1, N_WIRES_C2)}\n",
    "        c3_weight_shapes = {\"weights\": (1, N_WIRES_C3)}\n",
    "        self.c1_layer = qml.qnn.TorchLayer(C1, c1_weight_shapes)\n",
    "        self.c2_layer = qml.qnn.TorchLayer(C2, c2_weight_shapes)\n",
    "        self.c3_layer = qml.qnn.TorchLayer(C3, c3_weight_shapes)\n",
    "        \n",
    "    def forward(self, d1, d2):\n",
    "        \n",
    "        ### Branch 1\n",
    "        c1_out = self.c1_layer(d1).float()\n",
    "        \n",
    "        ### Branch 2\n",
    "        f2_out = self.f2(d2)\n",
    "        c2_out = self.c2_layer(f2_out).float()\n",
    "        \n",
    "        ### Join outputs of c1 and f2 for c3\n",
    "        c3_in = torch.cat([c1_out, c2_out], dim=1)\n",
    "        c3_out = self.c3_layer(c3_in).float() \n",
    "        \n",
    "        ### Final result through a simple classical linear transformation\n",
    "        #   For more complex matrix transform, we can use torch.matmul()\n",
    "        final_output = self.m1(c3_out) \n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c16075-9df5-4d30-9a0e-d651aa53da18",
   "metadata": {},
   "source": [
    "## Model creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c18431da-eb74-4b97-94a3-2f1b918bbc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training\n",
      "\n",
      "Epoch  1, Loss: 0.5069\n",
      "Epoch  2, Loss: 0.4726\n",
      "Epoch  3, Loss: 0.4664\n",
      "Epoch  4, Loss: 0.4632\n",
      "Epoch  5, Loss: 0.4344\n",
      "Epoch  6, Loss: 0.4039\n",
      "Epoch  7, Loss: 0.3662\n",
      "Epoch  8, Loss: 0.3017\n",
      "Epoch  9, Loss: 0.2199\n",
      "Epoch 10, Loss: 0.1460\n",
      "Epoch 11, Loss: 0.1919\n",
      "Epoch 12, Loss: 0.0878\n",
      "Epoch 13, Loss: 0.0938\n",
      "Epoch 14, Loss: 0.0366\n",
      "Epoch 15, Loss: 0.0571\n",
      "Epoch 16, Loss: 0.0361\n",
      "Epoch 17, Loss: 0.0417\n",
      "Epoch 18, Loss: 0.0383\n",
      "Epoch 19, Loss: 0.0434\n",
      "Epoch 20, Loss: 0.0377\n",
      "\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "### For reproducibility\n",
    "seed = 2025\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "### Instantiate the model\n",
    "f = HybridF()\n",
    "\n",
    "### Create dummy data\n",
    "batch_size = 10\n",
    "d1_data = torch.randn(batch_size, N_FEATURES_D1)\n",
    "d2_data = torch.randn(batch_size, N_FEATURES_D2)\n",
    "labels = torch.randn(batch_size, 1)\n",
    "\n",
    "### Define loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(f.parameters(), lr=0.1)\n",
    "\n",
    "### Training loop\n",
    "epochs = 20\n",
    "print('\\nStarting training\\n')\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = f(d1_data, d2_data)\n",
    "    loss = loss_fn(predictions, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch+1:2d}, Loss: {loss.item():0.4f}')\n",
    "\n",
    "print('\\nTraining complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfbacb6-8ec5-44fe-b496-ea42caf3ac6f",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed62ab9a-1a16-43e7-80ce-c454ff575824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09331846],\n",
       "       [ 0.46699953],\n",
       "       [-0.5923619 ],\n",
       "       [ 0.2560212 ],\n",
       "       [-0.32537133]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### For reproducibility\n",
    "seed = 2025\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "### New data\n",
    "test_batch_size = 5\n",
    "d1_test = torch.randn(test_batch_size, N_FEATURES_D1)\n",
    "d2_test = torch.randn(test_batch_size, N_FEATURES_D2)\n",
    "\n",
    "### Function application and result is an array\n",
    "f(d1_test, d2_test).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7d4980-079c-4b84-b7a3-b73daaa0dd04",
   "metadata": {},
   "source": [
    "## Systems in use (Linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30cddc6d-205d-493e-bb9f-02f7c98cefc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pennylane                 0.42.3\n",
      "pennylane_lightning       0.42.0\n",
      "torch                     2.8.0\n",
      "torchaudio                2.8.0\n",
      "torcheval                 0.0.7\n",
      "torchmetrics              1.8.2\n",
      "torchsummary              1.5.1\n",
      "torchvision               0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -e pennylane -e torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
